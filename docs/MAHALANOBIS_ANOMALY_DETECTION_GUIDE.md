# マハラノビス距離による異常検知運用ガイド

## 概要

少数標本（12件）でのOCR品質監視のため、マハラノビス距離ベースの異常検知システムを導入。統計的に堅実な手法で「探索→監視」用途として実用レベルに到達。

## 閾値設定（D²ベース）

### 距離単位の統一
- **すべてD²（距離の2乗）で統一**
- 理論線：χ²(df=8) の95%点 = **15.51 D²**
- 経験線：ブートストラップ95%点 = **53.00 D²**
- 準異常線：中間値 = **25.0 D²**

### 運用閾値ルール

| 範囲 | レベル | 対応アクション | 判定根拠 |
|-----|-------|---------------|----------|
| D² ≤ 25 | **通常運転** | 標準処理続行 | 正常範囲内 |
| 25 < D² ≤ 53 | **準異常（要観察）** | ログ記録・閾値緩和なし | 統計的な逸脱だが許容範囲 |
| D² > 53 | **強い異常（デグレード）** | 前処理強化→再試行→フォールバック | 経験的に異常と判定 |

## 8次元特徴量

1. **CER** - Character Error Rate（主要品質指標）
2. **latency_ms** - 総処理時間
3. **detected_chars** - 検出文字数
4. **ground_truth_chars** - 正解文字数
5. **confidence** - OCR信頼度
6. **dt_boxes_count** - 検出ボックス数
7. **ocr_ms** - OCR処理時間
8. **post_ms** - 後処理時間

## 実装詳細

### 共分散推定
- **Ledoit-Wolf推定器**を採用（少数標本に適用）
- Leave-One-Out方式でバイアス低減

### タグ別分析
タグによって分布特性が異なるため、サンプル数が20を超えたらタグ別再推定を推奨：

- `clean` - 最も安定
- `dense` - 文字密度高、やや不安定
- `lowcontrast` - 品質劣化しやすい
- `small` - サイズ起因の課題
- `mono-code` - 等幅フォント特有の問題

## 運用フロー

### 1. リアルタイム判定
```python
distance_d2 = compute_mahalanobis_distance(features)

if distance_d2 > 53.0:
    # 強い異常：デグレード対応
    apply_preprocessing_enhancement()
    if still_failed:
        fallback_to_alternative_method()
elif distance_d2 > 25.0:
    # 準異常：要観察
    log_warning("準異常検知", distance_d2)
    continue_with_standard_threshold()
else:
    # 通常運転
    continue_normal_processing()
```

### 2. ログ出力

各リクエストで以下をJSONL形式で記録：

```json
{
  "timestamp": "2025-11-03T04:41:22.787518",
  "image_id": "012",
  "tag": "lowcontrast-dense",
  "features_raw": {...},
  "anomaly_detection": {
    "mahal_distance_d2": 101.65,
    "cov_version": "ledoit_wolf",
    "thresholds": {"theory_d2": 15.51, "empirical_d2": 53.0, "warning_d2": 25.0},
    "level": "strong_anomaly",
    "decision": "degrade",
    "rationale": "D²=101.65 vs 閾値=53.0"
  },
  "quality_metrics": {...},
  "performance": {...}
}
```

### 3. ダッシュボード監視

- **距離分布ヒストグラム**：全体の異常率トレンド
- **タグ別箱ひげ図**：カテゴリ別の品質傾向
- **QQプロット**：正規性仮定の妥当性確認
- **CER vs 距離散布図**：品質と異常度の相関

## ストレステスト管理

### 012問題の解決

画像012（lowcontrast-dense, CER=0.92, D²=101.6）は**意図的な困難画像**として有効だが、回帰テストの合格率を不当に悪化させる。

**分離戦略**：
- **回帰テストセット**：品質維持確認用（012除外）
- **ストレステストセット**：耐障害性確認用（012含む）

### 実装例

```python
# 分離実行
python tools/visualize_ocr_results.py --exclude_stress  # 回帰用
python tools/visualize_ocr_results.py --stress_only     # ストレス用（要実装）
```

## 継続改善

### 短期（1-2週間）
1. タグ別閾値の微調整
2. 前処理強化ルールの最適化
3. フォールバック品質の検証

### 中期（1-2ヶ月）
1. サンプル数増加時のタグ別モデリング
2. Box-Cox変換による分布正規化
3. 季節性・経時変化の監視

### 長期（3-6ヶ月）
1. 新しいOCRエンジン統合時の再校正
2. 画像種別の自動分類
3. 動的閾値調整

## 成功指標

- **誤検知率** < 5%（通常画像を異常判定）
- **見逃し率** < 10%（異常画像を通常判定）
- **処理時間影響** < 1%（計算オーバーヘッド）
- **運用保守性**：分析レポート自動生成

## トラブルシューティング

### よくある問題

1. **距離が異常に高い**
   - 特徴量のスケール確認
   - 外れ値の除外検討
   - 共分散行列の条件数確認

2. **QQプロットが直線から外れる**
   - タグ別分離の検討
   - 変換（log, sqrt, Box-Cox）適用
   - 分布仮定の見直し

3. **閾値が実運用に合わない**
   - サンプル追加後の再推定
   - ビジネス要件との調整
   - A/Bテストによる検証

---

**統計は嫌いでも、データはうそをつかない。堅実に運用していこう。** 📊