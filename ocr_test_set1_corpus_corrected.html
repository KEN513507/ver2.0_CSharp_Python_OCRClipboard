<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<title>OCRテストセットset1向けテキストコーパス（改善版）</title>
<style>
  body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    margin: 20px;
    color: #000;
  }
  h1, h2, h3 {
    color: #333;
  }
  table {
    border-collapse: collapse;
    width: 100%;
    margin-bottom: 20px;
  }
  th, td {
    border: 1px solid #ccc;
    padding: 8px;
    text-align: left;
  }
  th {
    background-color: #f2f2f2;
  }
  /* Custom styles for test cases */
  .small {
    font-size: 11pt;
  }
  .large {
    font-size: 18pt;
  }
  .dense {
    line-height: 1.0;
  }
  .lowcontrast {
    background-color: #ffffff;
    color: #999999;
    padding: 10px;
  }
  .invert {
    background-color: #333333;
    color: #ffffff;
    padding: 10px;
  }
  .tilt2 {
    display: inline-block;
    transform: rotate(2deg);
  }
  .mono {
    font-family: monospace;
    white-space: pre-wrap;
  }
</style>
</head>
<body>

<h1>OCRテストセットset1向けテキストコーパス（改善版）</h1>

<h2>I. 序論：OCRテストセットset1向けにキュレーションされたテキストコーパス</h2>

<h3>A. 本ドキュメントの目的</h3>
<p>
本ドキュメントは、提示された技術仕様書「Test Image Set Plan」に完全準拠した、12組の画像・テキストデータペアの正解テキスト（グラウンドトゥルース）を提供することを主目的とします。ここに収録されるコーパスは、単に仕様を満たすだけでなく、定義されたテストパターンを戦略的に実行し、対象となるOCRシステムの能力を厳格に評価するために設計されています。各テキストサンプルは、特定のOCR機能（例：言語モデル、レイアウト解析、画像前処理）に負荷をかけるよう意図的に選定・作成されており、これによりシステムの堅牢性、精度、および回帰テストにおける信頼性を多角的に検証することが可能となります。
</p>

<h3>B. コンテンツのソースとライセンス</h3>
<p>
テストセットの法的完全性を保証するため、本コーパスで利用されるすべてのテキストコンテンツは、著作権フリーおよびパブリックドメインのソースから引用されています。日本語テキストの主要なソースは、パブリックドメインの文学作品を収集・公開している青空文庫です。具体的には、夏目漱石の『吾輩は猫である』から抜粋しています。同様に、英語テキストは、著作権の消滅した作品を電子化するプロジェクト・グーテンベルクから引用しており、ルイス・キャロルの『不思議の国のアリス』（Alice's Adventures in Wonderland）をソースとしています。これらのソースは、そのライセンス条件に基づき、このようなテストデータセットへの利用が許可されています。
</p>
<p>
古典文学作品の選定は、単にテキストを提供する以上の戦略的な意味を持ちます。例えば、夏目漱石の文章は、現代の簡略化された日本語とは異なる明治時代の文体や豊富な語彙を含んでおり、OCRの日本語言語モデルに対してより複雑な課題を提示します。同様に、ルイス・キャロルの作品は、一般的な散文に加えて会話文や独特の言葉遊びを多用しており、乾いた技術文書よりも広範な英語の言語的特徴を試すことができます。この選定により、本データセットは単純な文字認識テストから、より総合的な言語的・文脈的評価へと昇華されています。
</p>

<h3>C. 本成果物の構成</h3>
<p>
本ドキュメントは以下のセクションで構成されます。まず、12組の各データペアについて、そのファイル名、メタデータ、選定・作成の論理的根拠、そして画像化の元となる正解テキストを詳述します。次に、箇条書きや表形式テキストといった複雑なパターンの構築手法について深掘りします。最後に、画像生成時の具体的な実装ガイダンスと、テスト自動化を円滑にするための完成したデータセットマニフェストファイルを提供し、結論で締めくくります。
</p>

<h2>II. テストデータの内容と論理的根拠（サンプル001-012）</h2>
<p>
以下に、テストセットset1を構成する12のテキストサンプルを詳述します。各サンプルは、ファイル名、メタデータ、内容の論理的根拠、そして画像化の際に使用する正解テキスト（グラウンドトゥルース）から成ります。
</p>

<h3>A. サンプル001：標準的な日本語の段落</h3>
<p><strong>ファイル:</strong> 001__JP__clean.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=clean, chars=248</p>
<p>
<strong>内容の論理的根拠:</strong> 夏目漱石『吾輩は猫である』の冒頭部分から引用したこのテキストは、日本語散文認識のベースラインとして機能します。漢字、ひらがな、カタカナが標準的な比率で含まれ、句読点（「。」、「、」）も適切に配置されています。明確な段落構造を持ち、OCRシステムの基本的な日本語処理能力を検証するための理想的な出発点となります。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="clean">
吾輩は猫である。名前はまだ無い。どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。
</p>

<h3>B. サンプル002：高密度の日本語の段落</h3>
<p><strong>ファイル:</strong> 002__JP__clean-dense.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=clean-dense, chars=366</p>
<p>
<strong>内容の論理的根拠:</strong> より長い文章ブロックに対するOCRの性能をテストするため、長めの段落を選定しました。denseタグは、画像生成時に行間を通常より狭くすることを意図しています。これにより、隣接する行の文字のバウンディングボックスが近接、あるいは部分的に重なる状況を作り出します。これは特にOCRの行セグメンテーション（行分割）アルゴリズムにとって大きな挑戦となり、その堅牢性を評価する上で重要なテストケースです。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="dense">
元来この主人は何といって人に勝れて出来る事もないが、何にでもよく手を出したがる。俳句をやってほととぎすへ投稿したり、新体詩を明星へ送ったり、間違いだらけの英文をかいたり、時によると弓に凝ったり、謡をうたったり、ヴァイオリンを弾いたりするが、気の毒な事には、どれもこれも物になっておらん。その癖やり出すと大変な熱心さで、後架の中で謡をうたって、近所迷惑もかまわず、日の出から日の入りまでやり通すくらいの根気はある。彼は純粋の黒猫である。わずかに午を過ぎたる太陽は、透明なる光線を彼の皮膚の上に抛げかけて、きらきらする柔毛の間より眼に見えぬ炎でも燃え出ずるように思われた。彼は猫中の大王とも云うべきほどの偉大なる体格を有している。吾輩の倍はたしかにある。
</p>

<h3>C. サンプル003：小フォント・漢字多めのテキスト</h3>
<p><strong>ファイル:</strong> 003__JP__small.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=small, chars=161</p>
<p>
<strong>内容の論理的根拠:</strong> このサンプルは、日本の著作権法第一条および第二十一条から引用しています。法律文書は意図的に選ばれており、その特徴は「著作物」「頒布」「許諾」「専有」といった画数の多い複雑な漢字が高い密度で出現することです。これをsmallタグの指示通り小さいフォントサイズで画像化すると、文字の細い線が潰れたり隣接する線と融合したりする可能性が高まります。これは、劣化した条件下で複雑な文字の特徴を正確に抽出するOCRモデルの能力を直接的に試すものです。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="small">
第一条 この法律は、著作物並びに実演、レコード、放送及び有線放送に関し著作者の権利及びこれに隣接する権利を定め、これらの文化的所産の公正な利用に留意しつつ、著作者等の権利の保護を図り、もつて文化の発展に寄与することを目的とする。第二十一条 著作者は、その著作物を複製する権利を専有する。
</p>

<h3>D. サンプル004：大フォント・かな多めのテキスト</h3>
<p><strong>ファイル:</strong> 004__JP__large.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=large, chars=190</p>
<p>
<strong>内容の論理的根拠:</strong> 前のサンプルとの対照をなすため、このテキストはひらがなの比率が高い会話文から構成されています。largeタグの指示通り大きなフォントサイズ（例：18pt）で表示すると、文字のエッジがピクセル化したり、予期せぬ形状になったりすることがあり、これは小フォントとは異なる種類の課題をOCRエンジンに与えます。このサンプルは、フォントサイズや文字の複雑さといった広範なスペクトルにわたって、OCRが安定した性能を発揮できるかを検証します。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="large">
「あらまあ、きれいな猫。うちへいらっしゃい。御飯をあげますから」とか何とか云ってくれたんだ。あたしはいつでも人から御飯を貰う積りでいるから、別にその女に限り御馳走になろうという気もなかったんだが、何しろお腹がすいていた時だったもんだから、ついふらふらとくっ付いて行ったんだ。そうしたら大変な御馳走でね。鰹節の干したのを一本くれたわ。
</p>

<h3>E. サンプル005：低コントラストの日本語テキスト</h3>
<p><strong>ファイル:</strong> 005__JP__lowcontrast.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=lowcontrast, chars=280</p>
<p>
<strong>内容の論理的根拠:</strong> このテストの主眼はテキスト内容そのものではなく、lowcontrastタグが示す視覚的な劣化条件にあります。標準的な日本語の段落を用い、背景色と文字色の輝度差が小さい画像（例：白背景に薄い灰色の文字）を生成します。これはOCRエンジンの画像前処理能力、特に二値化アルゴリズムの性能を試すためのものです。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="lowcontrast">
人間と生れたら教師となるに限る。こんなに寝ていて勤まるものなら猫にでも出来ぬ事はないと。それでも主人に云わせると教師ほどつらいものはないそうで彼は友達が来る度に何とかかんとか不平を鳴らしている。吾輩がこの家へ住み込んだ当時は、主人以外のものにははなはだ不人望であった。どこへ行っても跳ね付けられて相手にしてくれるものは一人もなかった。吾輩は仕方がないから、出来得る限り吾輩を入れてくれた主人の傍にいる事をつとめた。
</p>

<h3>F. サンプル006：反転・小フォントのテキスト（重要回帰テストケース）</h3>
<p><strong>ファイル:</strong> 006__JP__invert-small.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=invert-small, chars=189</p>
<p>
<strong>内容の論理的根拠:</strong> このサンプルは、invertタグ画像で正規化スコア94%以上という性能ベンチマークに対応する重要なテストケースです。テキストは青空文庫の作品メタデータから引用しており、漢字、カタカナ、数字、括弧、日付が混在しています。invert（白文字・濃色背景）とsmall（小フォント）の組み合わせは、極性検出、ノイズ除去、微細な特徴認識といった複数の能力を同時に試す複合的な課題を生み出します。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="invert small">
作品名： 吾輩は猫である作品名読み： わがはいはねこである著者名： 夏目 漱石初出： 「ホトトギス」1905（明治38）年1月、2月、4月、6月、7月、10月、1906（明治39）年1月、3月、4月、8月底本： 夏目漱石全集1出版社： 筑摩書房初版発行日： 1971（昭和46）年4月5日
</p>

<h3>G. サンプル007：傾いた日本語テキスト</h3>
<p><strong>ファイル:</strong> 007__JP__tilt2.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=tilt2, chars=215</p>
<p>
<strong>内容の論理的根拠:</strong> このサンプルは、OCRの傾き補正アルゴリズムを直接テストします。標準的な日本語の段落を用い、tilt2タグの指示通り、画像全体を約2度回転させます。このような僅かな傾きは、堅牢性の低い前処理ステップでは見逃されやすく、より現実的で挑戦的なテストシナリオとなります。
</p>
<p><strong>正解テキスト:</strong></p>
<p class="tilt2">
車屋の黒はこの近辺で知らぬ者なき乱暴猫である。しかし車屋だけに強いばかりでちっとも教育がないからあまり誰も交際しない。同盟敬遠主義の的になっている奴だ。吾輩は彼の名を聞いて少々尻こそばゆき感じを起すと同時に、一方では少々軽侮の念も生じたのである。第一その顔つきが気に食わん。猫だといって、あんなに人間のまねをしたがる奴があるものか。
</p>

<h3>H. サンプル008：等幅フォントの日本語表形式テキスト</h3>
<p><strong>ファイル:</strong> 008__JP__mono-code.txt<br>
<strong>メタデータ:</strong> lang=JP, tags=mono-code, chars=242</p>
<p>
<strong>内容の論理的根拠:</strong> このテキストは「表風テキスト」という要件を満たすために合成されました。日本語のファイル名とメタデータを半角スペースを用いて桁を揃えています。monoタグが示す通り、日本語等幅フォントでの画像化が不可欠です。このテストは、OCRが空白（ホワイトスペース）を正確に保持する能力を検証します。
</p>
<p><strong>正解テキスト:</strong></p>
<pre class="mono">
ドキュメント/├── 吾輩は猫である_草稿.txt   (128 KB)
├── 登場人物リスト.md         (5 KB)
├── 研究ノート/
│   ├── 01_漱石の文体分析.docx (22 KB)
│   └── 02_猫の視点.pptx      (1.2 MB)
└── 資料画像/
    └── 黒猫の写真_003.jpg     (350 KB)
</pre>

<h3>I. サンプル009：標準的な英語の段落</h3>
<p><strong>ファイル:</strong> 009__EN__clean.txt<br>
<strong>メタデータ:</strong> lang=EN, tags=clean, chars=273</p>
<p>
<strong>内容の論理的根拠:</strong> 英語テキスト認識のベースラインとして機能します。『不思議の国のアリス』から引用したこの段落は、標準的な英文の構造、句読法、語彙を含んでおり、基本的な英語処理能力を検証するのに適しています。
</p>
<p><strong>正解テキスト:</strong></p>
<p>
Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do. Once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, "and what is the use of a book," thought Alice, "without pictures or conversations?"
</p>

<h3>J. サンプル010：英語のコードとURLが混在したテキスト</h3>
<p><strong>ファイル:</strong> 010__EN__mono-code.txt<br>
<strong>メタデータ:</strong> lang=EN, tags=mono-code, chars=246</p>
<p>
<strong>内容の論理的根拠:</strong> 「コード/URL混在」の要件に直接対応するサンプルです。C#のコードスニペットとプロジェクト・グーテンベルクのURLを組み合わせています。このテキストは、プログラミングや技術文書で頻出するものの、自然言語の文章では稀な英数字、記号（_, /, :, (, ), ;）、予約語が密集した状態を再現します。等幅フォント（Consolas）の使用が、正確なレンダリングとテストのために重要です。
</p>
<p><strong>正解テキスト:</strong></p>
<pre class="mono">
C#// C# Sample from documentation
// URL: https://www.gutenberg.org/
namespace CSharpApplication
{
    public static void CalculateSum()
    {
        int a = 42;
        int b = 119;
        int c = a + b;
        Console.WriteLine("The sum is: " + c);
    }
}
</pre>

<h3>K. サンプル011：日本語・英語混合テキスト</h3>
<p><strong>ファイル:</strong> 011__MIX__clean.txt<br>
<strong>メタデータ:</strong> lang=MIX, tags=clean, chars=248</p>
<p>
<strong>内容の論理的根拠:</strong> このサンプルは、技術文書などで見られる、日本語の文章中に英単語が埋め込まれている状況をシミュレートします。プロジェクト・グーテンベルクについて日本語で説明し、その中に "Project Gutenberg" や "Unicode" といった英語の固有名詞や専門用語を挿入しています。これは、同じテキストブロック内で言語モデルを正しく切り替えることができるか、という現代のOCRシステムにとって非常に重要な能力をテストします。
</p>
<p><strong>正解テキスト:</strong></p>
<p>
プロジェクト・グーテンベルク（Project Gutenberg）は、1971年に開始された最も歴史ある電子図書館である。その使命は「電子書籍の作成と配布を推進すること」であり、スローガンは「無学・無教養の垣根を取り壊す」ことである。著作権が消滅した作品を中心に収集しており、その数は数万点を超える。テキストは主にUnicodeで運営されており、世界中のボランティアによって電子化が進められている。
</p>

<h3>L. サンプル012：複雑な日本語・英語混合リスト</h3>
<p><strong>ファイル:</strong> 012__MIX__lowcontrast-dense.txt<br>
<strong>メタデータ:</strong> lang=MIX, tags=lowcontrast-dense, chars=300</p>
<p>
<strong>内容の論理的根拠:</strong> これは、複数の課題を組み合わせた最も複雑なサンプルです。「箇条書き」形式で、Project Gutenberg AustraliaやPG-EUといったプロジェクト・グーテンベルクの姉妹プロジェクトを列挙しています。これにより、言語混合（MIX）、構造化フォーマット（リスト）、視覚的劣化（lowcontrast, dense）が一体となります。これは、画像前処理、レイアウト解析、多言語文字認識というOCRパイプライン全体のストレステストとして機能します。
</p>
<p><strong>正解テキスト:</strong></p>
<pre class="lowcontrast dense">
プロジェクト・グーテンベルクには、特定の国や言語に焦点を当てた姉妹プロジェクトが多数存在する。
・Project Gutenberg Australia: オーストラリアの著作権法でパブリックドメインになったテキストを所収。
・PG-EU: EUの著作権法下で運営され、多くの言語を含めることを目的とする。Unicodeで運営されている。
・Project Gutenberg Luxembourg: 主にルクセンブルク語で書かれた書籍を公開。
・Projekti Lönnrot: フィンランドのボランティアによるプロジェクト。
</pre>

<h2>III. コンテンツパターンの詳細な構築手法</h2>

<h3>A. 構造的・記号的コンテンツの作成</h3>
<p>
散文以外のサンプルは、OCRの特定の機能をテストするために慎重に構築されています。
</p>
<ul>
  <li><strong>箇条書き（012）:</strong> 先頭記号（・）とそれに続くインデント（半角スペースによる）を用いてリスト構造を作成しました。これにより、レイアウト解析機能と、英数字以外の先頭文字を正しく保持する能力が試されます。</li>
  <li><strong>記号リッチなテキスト（010）:</strong> C#コードサンプルでは、算術演算子（+, =）、括弧（()）、区切り文字（;）などが含まれています。これらの記号は、一般的な単語に比べて学習データに出現する頻度が低いため、OCRモデルがこれらを正確に認識できるかどうかの良い指標となります。</li>
  <li><strong>表形式テキスト（008）:</strong> このサンプルでは、タブ文字ではなく、一貫した数の半角スペースを用いて桁を揃えました。これはコマンドラインツールの出力など、実際のプレーンテキストでよく見られる形式です。OCRの空間認識能力と、可変長の空白を単一の区切り文字として誤認識せずに、そのままの形で維持する能力が問われます。</li>
</ul>

<h3>B. 漢字・かなの対照戦略</h3>
<p>
仕様書で要求された「かな多めと漢字多めの対照」は、OCRモデルの異なる側面に焦点を当てるための戦略的なアプローチです。この対照により、モデルの弱点をより詳細に診断できます。漢字が密集したテキスト（サンプル003の法律文書など）は、数千種類も存在する、構造的に類似した複雑な文字群を区別するモデルの分類能力を試します。一方、かなが多いテキスト（サンプル004の会話文など）は、モデルのセグメンテーション能力と、単純ながら視覚的に似通った文字（例：「は」と「ほ」、「ね」と「わ」と「れ」）を区別する能力をテストします。この両極端のデータを提供することで、モデルの異なる種類の弱点を特定することが可能になります。
</p>

<h3>C. 現実世界を模した多言語シナリオ</h3>
<p>
サンプル011と012は、現代のデジタル環境の多言語性を反映して設計されています。技術マニュアル、ソフトウェアのUI、学術論文などでは、日本語と英語が混在するのが常です。このようなテキストを扱えないOCRは、実用性に欠けます。これらのサンプルは、OCRシステムの言語検出モジュールをテストします。特に、文書全体ではなく、行の一部や単語レベルで言語を検出し、適切な言語モデルを動的に適用できるかという、より高度な能力を検証することを目的としています。
</p>

<h2>IV. 実装ガイダンスとデータセット管理</h2>

<h3>A. 画像生成のためのベストプラクティス</h3>
<p>
提供されたテキストから.pngファイルを生成する際の具体的な推奨事項を以下に示します。
</p>
<ul>
  <li><strong>フォント:</strong> 仕様書で推奨されているフォントの使用を強く推奨します。標準的な日本語にはメイリオまたは游ゴシック、等幅日本語にはMS 明朝、英語コードにはConsolasが適しています。</li>
  <li><strong>フォントサイズ:</strong> smallタグには10pt〜11pt、largeタグには16pt〜20pt、それ以外は12ptを基準とすることを推奨します。</li>
  <li><strong>視覚効果:</strong>
    <ul>
      <li><em>lowcontrast:</em> 白背景に#999999の文字色、あるいは#333333の背景色に黒文字といった組み合わせを推奨します。ここでは白背景に薄い灰色の文字色を採用しています。</li>
      <li><em>dense:</em> テキストエディタやワードプロセッサで、行間を1.0（1行）またはそれ以下に設定してからスクリーンショットを取得してください。</li>
      <li><em>tilt2:</em> スクリーンショット取得後、画像編集ソフトウェアを使用して正確に2度の回転を適用してください。</li>
    </ul>
  </li>
</ul>

<h3>B. データセットマニフェスト (manifest.csv)</h3>
<p>
テストの自動化と管理を容易にするため、仕様書で提案されているmanifest.csvファイルを以下に提供します。このマニフェストは、run_polarity_batch.ps1のような自動検証スクリプトと直接連携できるように設計されています。事前に完成したマニフェストを提供することは、手動でのデータ入力ミスを防ぎ、テストパイプラインへの統合を円滑にします。これは、単なるデータ提供に留まらず、そのデータがユーザーのプロセスにおいてどのように活用されるかを理解した上での支援です。
</p>

<table>
  <thead>
    <tr>
      <th>id</th>
      <th>file</th>
      <th>lang</th>
      <th>tags</th>
      <th>chars_expected</th>
      <th>notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>001</td>
      <td>001__JP__clean.png</td>
      <td>JP</td>
      <td>clean</td>
      <td>248</td>
      <td>ベースライン日本語散文（漱石）</td>
    </tr>
    <tr>
      <td>002</td>
      <td>002__JP__clean-dense.png</td>
      <td>JP</td>
      <td>clean-dense</td>
      <td>366</td>
      <td>長文段落、行セグメンテーションのテスト</td>
    </tr>
    <tr>
      <td>003</td>
      <td>003__JP__small.png</td>
      <td>JP</td>
      <td>small</td>
      <td>161</td>
      <td>漢字多めの法律文、小フォントでの複雑文字認識テスト</td>
    </tr>
    <tr>
      <td>004</td>
      <td>004__JP__large.png</td>
      <td>JP</td>
      <td>large</td>
      <td>190</td>
      <td>かな多めの会話文、大フォントレンダリングのテスト</td>
    </tr>
    <tr>
      <td>005</td>
      <td>005__JP__lowcontrast.png</td>
      <td>JP</td>
      <td>lowcontrast</td>
      <td>280</td>
      <td>画像前処理および二値化アルゴリズムのテスト</td>
    </tr>
    <tr>
      <td>006</td>
      <td>006__JP__invert-small.png</td>
      <td>JP</td>
      <td>invert-small</td>
      <td>189</td>
      <td>重要回帰ケース：極性反転＋小フォント＋記号</td>
    </tr>
    <tr>
      <td>007</td>
      <td>007__JP__tilt2.png</td>
      <td>JP</td>
      <td>tilt2</td>
      <td>215</td>
      <td>僅かな傾きに対する傾き補正アルゴリズムのテスト</td>
    </tr>
    <tr>
      <td>008</td>
      <td>008__JP__mono-code.png</td>
      <td>JP</td>
      <td>mono-code</td>
      <td>242</td>
      <td>表形式テキスト、空白文字の保持能力テスト</td>
    </tr>
    <tr>
      <td>009</td>
      <td>009__EN__clean.png</td>
      <td>EN</td>
      <td>clean</td>
      <td>273</td>
      <td>ベースライン英語散文（キャロル）</td>
    </tr>
    <tr>
      <td>010</td>
      <td>010__EN__mono-code.png</td>
      <td>EN</td>
      <td>mono-code</td>
      <td>246</td>
      <td>C#コードとURLの混在、記号と英数字連続のテスト</td>
    </tr>
    <tr>
      <td>011</td>
      <td>011__MIX__clean.png</td>
      <td>MIX</td>
      <td>clean</td>
      <td>248</td>
      <td>言語切り替えテスト（日本語＋埋め込み英語）</td>
    </tr>
    <tr>
      <td>012</td>
      <td>012__MIX__lowcontrast-dense.png</td>
      <td>MIX</td>
      <td>lowcontrast-dense</td>
      <td>300</td>
      <td>複合ストレステスト：リスト、多言語、視覚的劣化</td>
    </tr>
  </tbody>
</table>

<h2>V. 結論：厳格なOCR評価のための基盤</h2>

<h3>A. 成果物の要約</h3>
<p>
本ドキュメントは、OCRシステムの検証用に設計されたテストセットset1のための、12組の高品質な正解テキストサンプルを提供しました。各サンプルは、ユーザーの技術仕様に厳密に従い、その選定・作成の論理的根拠と共に詳述されています。さらに、テストの自動化を促進するための完成したCSVマニフェストも含まれています。
</p>

<h3>B. 次のステップと将来的な拡張</h3>
<p>
今回提供されたset1は、OCRシステムの回帰テストにおける堅牢な基盤を形成します。将来的なテストセット（set2以降）では、これらのパターンをさらに拡張することが考えられます。例えば、複数段組のレイアウト、手書き文字に近いフォント、あるいはスクリーンショットではなくスマートフォンで撮影した写真のような、よりノイズの多い画像の導入などが挙げられます。
</p>

<h3>C. 最終的な見解</h3>
<p>
提供されたテキストコーパスは、OCRシステムの性能を多角的かつ包括的に検証することを可能にします。ベースライン性能の確認から、特定の弱点の特定、そして現実世界の複雑なシナリオにおける堅牢性の評価まで、このデータセットはOCRの品質向上と信頼性確保に大きく貢献するものと確信しています。
</p>

</body>
</html>
