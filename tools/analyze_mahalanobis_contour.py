"""ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ã«ã‚ˆã‚‹å¤–ã‚Œå€¤åˆ†æï¼ˆçµ±è¨ˆçš„ã«å …ç‰¢ãªç‰ˆï¼‰"""
import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from scipy.spatial.distance import mahalanobis
from scipy.stats import chi2
from sklearn.decomposition import PCA
from sklearn.covariance import LedoitWolf
from sklearn.preprocessing import RobustScaler
import warnings

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Meiryo']
plt.rcParams['axes.unicode_minus'] = False
warnings.filterwarnings('ignore', category=RuntimeWarning)


def extract_text_features(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
    if not text:
        return np.zeros(8)
    
    total_chars = len(text)
    hiragana = sum(1 for c in text if '\u3040' <= c <= '\u309F')
    katakana = sum(1 for c in text if '\u30A0' <= c <= '\u30FF')
    kanji = sum(1 for c in text if '\u4E00' <= c <= '\u9FFF')
    ascii = sum(1 for c in text if ord(c) < 128)
    digit = sum(1 for c in text if c.isdigit())
    space = sum(1 for c in text if c.isspace())
    symbol = total_chars - (hiragana + katakana + kanji + ascii)
    
    return np.array([
        total_chars,
        hiragana / total_chars if total_chars > 0 else 0,
        katakana / total_chars if total_chars > 0 else 0,
        kanji / total_chars if total_chars > 0 else 0,
        ascii / total_chars if total_chars > 0 else 0,
        digit / total_chars if total_chars > 0 else 0,
        space / total_chars if total_chars > 0 else 0,
        symbol / total_chars if total_chars > 0 else 0,
    ])


def load_expected_texts():
    """æ­£è§£ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    root = Path("test_images/set1")
    expected = {}
    
    for i in range(1, 13):
        file_id = f"{i:03d}"
        # manifest.csvã‹ã‚‰æ­£è§£ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—
        txt_files = [
            "001__JP__clean.txt",
            "002__JP__clean-dense.txt",
            "003__JP__small.txt",
            "004__JP__large.txt",
            "005__JP__lowcontrast.txt",
            "006__JP__invert-small.txt",
            "007__JP__tilt2.txt",
            "008__JP__mono-code.txt",
            "009__EN__clean.txt",
            "010__EN__mono-code.txt",
            "011__MIX__clean.txt",
            "012__MIX__lowcontrast-dense.txt"
        ]
        
        if i <= len(txt_files):
            txt_path = root / txt_files[i-1]
            if txt_path.exists():
                expected[file_id] = txt_path.read_text(encoding='utf-8')
    
    return expected


def compute_loo_distances(X):
    """Leave-One-Out ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ï¼ˆè‡ªå·±æœ‰åˆ©ãƒã‚¤ã‚¢ã‚¹é™¤å»ï¼‰"""
    n = len(X)
    loo_distances = []
    
    for i in range(n):
        # iç•ªç›®ã‚’é™¤å¤–ã—ã¦å¹³å‡ãƒ»å…±åˆ†æ•£æ¨å®š
        X_loo = np.delete(X, i, axis=0)
        mean_loo = X_loo.mean(axis=0)
        
        # Ledoit-Wolfæ­£å‰‡åŒ–ï¼ˆnå°ã§ã‚‚å®‰å®šï¼‰
        lw = LedoitWolf()
        lw.fit(X_loo)
        precision = lw.precision_
        
        # ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢
        diff = X[i] - mean_loo
        d = np.sqrt(diff @ precision @ diff)
        loo_distances.append(d)
    
    return np.array(loo_distances)


def bootstrap_threshold(X, n_boot=1000, alpha=0.95):
    """ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã«ã‚ˆã‚‹çµŒé¨“çš„é–¾å€¤ç®—å‡º"""
    n, d = X.shape
    boot_max_distances = []
    
    for _ in range(n_boot):
        # å†æ¨™æœ¬åŒ–
        idx = np.random.choice(n, n, replace=True)
        X_boot = X[idx]
        
        # LOOè·é›¢è¨ˆç®—
        distances = compute_loo_distances(X_boot)
        boot_max_distances.append(np.max(distances))
    
    # 95%ç‚¹ã‚’é–¾å€¤ã¨ã™ã‚‹
    threshold = np.percentile(boot_max_distances, alpha * 100)
    return threshold


def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    json_path = Path("tests/outputs/ocr_dataset_eval.json")
    with open(json_path, 'r', encoding='utf-8') as f:
        results = json.load(f)
    
    expected_texts = load_expected_texts()
    
    # ç‰¹å¾´é‡æŠ½å‡º
    features = []
    ids = []
    cer_values = []
    tags_list = []
    
    for r in results:
        file_id = r['id']
        if file_id in expected_texts:
            feat = extract_text_features(expected_texts[file_id])
            features.append(feat)
            ids.append(file_id)
            cer_values.append(r['cer'])
            tags_list.append(r.get('tags', ''))
    
    X_raw = np.array(features)
    
    # 1. NaN/å®šæ•°åˆ—ãƒã‚§ãƒƒã‚¯
    valid_cols = []
    for j in range(X_raw.shape[1]):
        col = X_raw[:, j]
        if not np.any(np.isnan(col)) and np.std(col) > 1e-10:
            valid_cols.append(j)
    
    X_clean = X_raw[:, valid_cols]
    print(f"ğŸ“Š ç‰¹å¾´é‡å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯")
    print(f"   å…ƒæ¬¡å…ƒ: {X_raw.shape[1]} â†’ æœ‰åŠ¹æ¬¡å…ƒ: {X_clean.shape[1]}")
    
    # 2. ãƒ­ãƒã‚¹ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆmedian/IQRï¼‰
    scaler = RobustScaler()
    X = scaler.fit_transform(X_clean)
    
    # 3. LOOè·é›¢è¨ˆç®—ï¼ˆè‡ªå·±æœ‰åˆ©ãƒã‚¤ã‚¢ã‚¹é™¤å»ï¼‰
    loo_distances = compute_loo_distances(X)
    
    # 4. ç†è«–çš„é–¾å€¤ï¼ˆLedoit-Wolfå…±åˆ†æ•£ã®rankä½¿ç”¨ï¼‰
    lw = LedoitWolf()
    lw.fit(X)
    cov_rank = np.linalg.matrix_rank(lw.covariance_)
    threshold_theory = np.sqrt(chi2.ppf(0.95, df=cov_rank))
    
    # 5. ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—é–¾å€¤ï¼ˆçµŒé¨“çš„ï¼‰
    print(f"   ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ä¸­ï¼ˆ1000å›ï¼‰...", end='', flush=True)
    threshold_boot = bootstrap_threshold(X, n_boot=1000, alpha=0.95)
    print(f" å®Œäº†")
    
    # é–¾å€¤ã®æœ€çµ‚æ±ºå®šï¼ˆä¿å®ˆçš„ã«å¤§ãã„æ–¹ï¼‰
    threshold = max(threshold_theory, threshold_boot)
    
    print(f"\nğŸ“Š ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢åˆ†æï¼ˆLOO + æ­£å‰‡åŒ–ï¼‰")
    print(f"   æœ‰åŠ¹ç‰¹å¾´é‡æ¬¡å…ƒ: {X.shape[1]} (å…±åˆ†æ•£rank={cov_rank})")
    print(f"   ç†è«–é–¾å€¤ï¼ˆÏ‡Â²â‚{cov_rank},0.95â‚ï¼‰: {threshold_theory:.3f}")
    print(f"   çµŒé¨“é–¾å€¤ï¼ˆbootstrap 95%ï¼‰: {threshold_boot:.3f}")
    print(f"   æ¡ç”¨é–¾å€¤ï¼ˆä¿å®ˆçš„ï¼‰: {threshold:.3f}\n")
    
    for file_id, d, cer, tags in zip(ids, loo_distances, cer_values, tags_list):
        status = "âš ï¸å¤–ã‚Œå€¤" if d > threshold else "âœ…æ­£å¸¸"
        print(f"   {file_id} ({tags:20s}): LOOè·é›¢={d:.3f} CER={cer:.3f} {status}")
    
    # PCAã§2æ¬¡å…ƒã«æŠ•å½±
    pca = PCA(n_components=2)
    X_2d = pca.fit_transform(X)
    
    # QQãƒ—ãƒ­ãƒƒãƒˆç”¨ã«DÂ²ã‚’Ï‡Â²åˆ†å¸ƒã¨æ¯”è¼ƒ
    d_squared = loo_distances ** 2
    d_squared_sorted = np.sort(d_squared)
    theoretical_quantiles = chi2.ppf(np.linspace(0.01, 0.99, len(d_squared_sorted)), df=cov_rank)
    
    # å¯è¦–åŒ–
    fig, axes = plt.subplots(2, 2, figsize=(16, 14))
    
    # å·¦ä¸Š: PCAæ•£å¸ƒå›³ï¼ˆ8Dè·é›¢ã‚’è‰²ã§è¡¨ç¾ï¼‰
    ax = axes[0, 0]
    scatter = ax.scatter(X_2d[:, 0], X_2d[:, 1], c=loo_distances, cmap='coolwarm', 
                         s=150, alpha=0.8, edgecolors='black', linewidth=1.5)
    
    for i, (x, y) in enumerate(X_2d):
        ax.annotate(ids[i], (x, y), fontsize=9, ha='right', fontweight='bold')
    
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('LOO ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢', fontsize=11)
    
    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)
    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)
    ax.set_title('PCA 2DæŠ•å½±ï¼ˆè‰²=8æ¬¡å…ƒLOOè·é›¢ï¼‰', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # å³ä¸Š: LOOè·é›¢ vs CER
    ax = axes[0, 1]
    colors = ['red' if d > threshold else 'blue' for d in loo_distances]
    ax.scatter(loo_distances, cer_values, c=colors, s=120, alpha=0.7, edgecolors='black', linewidth=1.5)
    
    for i, (d, cer) in enumerate(zip(loo_distances, cer_values)):
        ax.annotate(ids[i], (d, cer), fontsize=9, ha='left')
    
    ax.axvline(threshold_theory, color='orange', linestyle=':', linewidth=2, label=f'ç†è«–é–¾å€¤={threshold_theory:.2f}')
    ax.axvline(threshold_boot, color='green', linestyle='-.', linewidth=2, label=f'çµŒé¨“é–¾å€¤={threshold_boot:.2f}')
    ax.axvline(threshold, color='red', linestyle='--', linewidth=2.5, label=f'æ¡ç”¨é–¾å€¤={threshold:.2f}')
    ax.set_xlabel('LOO ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢', fontsize=12)
    ax.set_ylabel('CER', fontsize=12)
    ax.set_title('è·é›¢ vs OCRç²¾åº¦ï¼ˆ3ç¨®ã®é–¾å€¤æ¯”è¼ƒï¼‰', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(fontsize=10)
    
    # å·¦ä¸‹: QQãƒ—ãƒ­ãƒƒãƒˆï¼ˆDÂ² vs Ï‡Â²åˆ†å¸ƒï¼‰
    ax = axes[1, 0]
    ax.scatter(theoretical_quantiles, d_squared_sorted, s=80, alpha=0.7, edgecolors='black')
    
    # ç†æƒ³ç·šï¼ˆy=xï¼‰
    lim_max = max(theoretical_quantiles.max(), d_squared_sorted.max())
    ax.plot([0, lim_max], [0, lim_max], 'r--', linewidth=2, label='ç†æƒ³ç·š (y=x)')
    
    for i, (tq, ds) in enumerate(zip(theoretical_quantiles[::2], d_squared_sorted[::2])):
        if i % 2 == 0:
            ax.annotate(ids[np.where(d_squared == ds)[0][0]], (tq, ds), fontsize=8, alpha=0.6)
    
    ax.set_xlabel(f'Ï‡Â²åˆ†å¸ƒ ç†è«–åˆ†ä½ç‚¹ (df={cov_rank})', fontsize=12)
    ax.set_ylabel('è¦³æ¸¬ DÂ² åˆ†ä½ç‚¹', fontsize=12)
    ax.set_title('QQãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¤šå¤‰é‡æ­£è¦æ€§æ¤œè¨¼ï¼‰', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend()
    
    # å³ä¸‹: è·é›¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    ax = axes[1, 1]
    sorted_idx = np.argsort(loo_distances)[::-1]
    sorted_ids = [ids[i] for i in sorted_idx]
    sorted_distances = loo_distances[sorted_idx]
    sorted_colors = ['red' if d > threshold else 'blue' for d in sorted_distances]
    
    y_pos = np.arange(len(sorted_ids))
    ax.barh(y_pos, sorted_distances, color=sorted_colors, alpha=0.7, edgecolor='black')
    ax.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'é–¾å€¤={threshold:.2f}')
    
    ax.set_yticks(y_pos)
    ax.set_yticklabels(sorted_ids, fontsize=10)
    ax.set_xlabel('LOO ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢', fontsize=12)
    ax.set_title('è·é›¢ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆé™é †ï¼‰', fontsize=13, fontweight='bold')
    ax.grid(True, alpha=0.3, axis='x')
    ax.legend()
    
    plt.tight_layout()
    plt.savefig('tests/outputs/ocr_mahalanobis_robust.png', dpi=300, bbox_inches='tight')
    print(f"\nâœ… å …ç‰¢ã‚°ãƒ©ãƒ•ä¿å­˜: tests/outputs/ocr_mahalanobis_robust.png")


if __name__ == "__main__":
    main()
